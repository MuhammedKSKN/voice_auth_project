import streamlit as st
import numpy as np
import librosa
import tensorflow as tf
import noisereduce as nr
import io
import soundfile as sf
import matplotlib.pyplot as plt
import os

# --- KERAS IMPORTS (Modeli yeniden inÅŸa etmek iÃ§in) ---
from tensorflow.keras import layers, models, backend as K
from tensorflow.keras.regularizers import l2

# ============================================================================
# 1. AYARLAR VE SABÄ°TLER
# ============================================================================
st.set_page_config(page_title="Sesle Kimlik DoÄŸrulama", page_icon="ðŸŽ™ï¸", layout="wide")

SR = 16000
N_MFCC = 40
HOP_LENGTH = 512
MAX_LEN = 128  # 4 saniye iÃ§in CNN giriÅŸ boyutu

# ============================================================================
# 2. MODEL MÄ°MARÄ°SÄ° VE YÃœKLEME FONKSÄ°YONLARI
# ============================================================================

# --- Ã–zel Fonksiyonlar (Custom Layers/Loss) ---
def euclidean_distance(vects):
    x, y = vects
    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)
    return K.sqrt(K.maximum(sum_square, K.epsilon()))

def eucl_dist_output_shape(shapes):
    shape1, shape2 = shapes
    return (shape1[0], 1)

def contrastive_loss(y_true, y_pred):
    margin = 1.0
    square_pred = K.square(y_pred)
    margin_square = K.square(K.maximum(margin - y_pred, 0))
    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)

# --- Temel AÄŸ (Base Network) ---
def build_base_network(input_shape):
    input_layer = layers.Input(shape=input_shape)
    reg = l2(0.01)
    
    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=reg)(input_layer)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D((2, 2))(x)
    x = layers.Dropout(0.3)(x)
    
    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=reg)(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D((2, 2))(x)
    x = layers.Dropout(0.4)(x)
    
    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=reg)(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D((2, 2))(x)
    x = layers.Dropout(0.5)(x)
    
    x = layers.Flatten()(x)
    x = layers.Dense(256, activation='relu', kernel_regularizer=reg)(x)
    x = layers.Dropout(0.5)(x)
    x = layers.Dense(128, activation=None)(x)
    
    # Lambda katmanÄ± (L2 Normalize)
    x = layers.Lambda(lambda x: K.l2_normalize(x, axis=1))(x)
    
    return models.Model(input_layer, x, name="Shared_Encoder")

# --- Modeli YÃ¼kleyen Ana Fonksiyon (CACHE ile) ---
@st.cache_resource
def load_siamese_model_weights():
    # 1. Model yolunu bul
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # GitHub'da 'model' klasÃ¶rÃ¼ iÃ§indeyse:
    model_path = os.path.join(current_dir, "model", "siamese_model.h5")
    
    # Dosya kontrolÃ¼
    if not os.path.exists(model_path):
        st.error(f"âš ï¸ Model dosyasÄ± bulunamadÄ±: {model_path}")
        return None

    try:
        # 2. Mimarisi SÄ±fÄ±rdan Ä°nÅŸa Et
        input_shape_model = (N_MFCC, MAX_LEN, 1)
        base_network = build_base_network(input_shape_model)

        input_a = layers.Input(shape=input_shape_model, name="Left_Audio")
        input_b = layers.Input(shape=input_shape_model, name="Right_Audio")

        processed_a = base_network(input_a)
        processed_b = base_network(input_b)

        distance = layers.Lambda(euclidean_distance, output_shape=eucl_dist_output_shape, name="Euclidean_Distance")([processed_a, processed_b])

        model = models.Model(inputs=[input_a, input_b], outputs=distance)

        # 3. AÄŸÄ±rlÄ±klarÄ± YÃ¼kle (.h5 dosyasÄ±ndan)
        # Not: load_weights, tam model dosyasÄ± olsa bile aÄŸÄ±rlÄ±klarÄ± Ã§ekebilir.
        model.load_weights(model_path)
        
        # Derleme (Compile) - Tahmin iÃ§in ÅŸart deÄŸil ama iyi pratik
        model.compile(loss=contrastive_loss, optimizer='adam')
        
        print("âœ… Model mimarisi oluÅŸturuldu ve aÄŸÄ±rlÄ±klar yÃ¼klendi.")
        return model

    except Exception as e:
        st.error(f"âŒ Model oluÅŸturulurken hata: {e}")
        return None

# Modeli baÅŸlat
model = load_siamese_model_weights()

# ============================================================================
# 3. SES Ã–N Ä°ÅžLEME (Preprocessing)
# ============================================================================

def preprocess_audio_pipeline(audio_bytes, target_sr=SR, fixed_length_samples=SR*4): # 4 Saniye
    try:
        y, sr = sf.read(io.BytesIO(audio_bytes))
        
        # 1. Resample & Mono
        if sr != target_sr:
            y = librosa.resample(y=y, orig_sr=sr, target_sr=target_sr)
        if len(y.shape) > 1:
             y = librosa.to_mono(y)
        
        # 2. GÃ¼rÃ¼ltÃ¼ Azaltma
        try:
            y = nr.reduce_noise(y=y, sr=target_sr)
        except:
            pass # Ã‡ok kÄ±sa seslerde hata verirse geÃ§

        # 3. Sessizlik Silme
        y, _ = librosa.effects.trim(y, top_db=20)

        # 4. Sabit Uzunluk (4 sn / ~64000 samples)
        # Sizin kodunuzdaki mantÄ±k: MFCC boyutunu 128'e denk getirmek.
        # Burada Ã¶nce sesi padding yapÄ±yoruz.
        target_length = int(SR * 4.0) # 64000
        if len(y) > target_length:
             y = y[:target_length]
        else:
             y = np.pad(y, (0, target_length - len(y)), mode='constant')
            
        # 5. Normalizasyon
        y = librosa.util.normalize(y)

        return y
    except Exception as e:
        st.error(f"Ses iÅŸleme hatasÄ±: {e}")
        return None

def extract_features_mfcc(y, sr=SR):
    """
    Sizin kodunuzdaki extract_mfcc mantÄ±ÄŸÄ±yla birebir aynÄ±.
    Ã‡Ä±ktÄ±: (1, 40, 128, 1)
    """
    try:
        mfcc = librosa.feature.mfcc(
            y=y, 
            sr=sr, 
            n_mfcc=N_MFCC, 
            hop_length=HOP_LENGTH
        )
        
        # BoyutlandÄ±rma (128 width)
        if mfcc.shape[1] < MAX_LEN:
            pad_width = MAX_LEN - mfcc.shape[1]
            mfcc = np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant')
        else:
            mfcc = mfcc[:, :MAX_LEN]
            
        # Model giriÅŸi iÃ§in ÅŸekillendirme: (Batch, Height, Width, Channels)
        mfcc_reshaped = mfcc.reshape(1, N_MFCC, MAX_LEN, 1)
        return mfcc_reshaped, mfcc
    except Exception as e:
        st.error(f"MFCC hatasÄ±: {e}")
        return None, None

# ============================================================================
# 4. ARAYÃœZ (UI)
# ============================================================================

st.title("ðŸ›¡ï¸ Sesle Kimlik DoÄŸrulama Sistemi")
st.markdown("Siyam AÄŸÄ± (Siamese CNN) kullanÄ±larak geliÅŸtirilmiÅŸtir.")

# Yan MenÃ¼ AyarlarÄ±
st.sidebar.header("Ayarlar")
THRESHOLD = st.sidebar.slider("Karar EÅŸik DeÄŸeri (Threshold)", 0.0, 1.0, 0.1100, 0.001)
st.sidebar.info(f"SeÃ§ili EÅŸik: {THRESHOLD}")

col1, col2 = st.columns(2)

# SOL KOLON: REFERANS (ANCHOR)
with col1:
    st.header("1. Referans Ses")
    anchor_file = st.file_uploader("Yetkili Sesi YÃ¼kle", type=["wav", "mp3"], key="anchor")
    
    feat_ref = None
    if anchor_file:
        st.audio(anchor_file)
        y_ref = preprocess_audio_pipeline(anchor_file.getvalue())
        if y_ref is not None:
            feat_ref, viz_ref = extract_features_mfcc(y_ref)
            st.success("Referans iÅŸlendi.")

# SAÄž KOLON: TEST (INPUT)
with col2:
    st.header("2. Test Sesi")
    # Hem dosya yÃ¼kleme hem mikrofon seÃ§eneÄŸi
    input_method = st.radio("GiriÅŸ YÃ¶ntemi:", ["Dosya YÃ¼kle", "Mikrofon"])
    
    test_file = None
    if input_method == "Dosya YÃ¼kle":
        test_file = st.file_uploader("ÅžÃ¼pheli Sesi YÃ¼kle", type=["wav", "mp3"], key="test")
    else:
        test_file = st.audio_input("Mikrofonla Kaydet")

    feat_test = None
    if test_file:
        st.audio(test_file)
        y_test = preprocess_audio_pipeline(test_file.getvalue())
        if y_test is not None:
            feat_test, viz_test = extract_features_mfcc(y_test)
            st.success("Test sesi iÅŸlendi.")

# DOÄžRULAMA BUTONU
st.divider()
if st.button("ðŸ” KÄ°MLÄ°ÄžÄ° DOÄžRULA", use_container_width=True, type="primary"):
    if model is None:
        st.error("Model yÃ¼klenemedi!")
    elif feat_ref is None or feat_test is None:
        st.warning("LÃ¼tfen her iki sesi de yÃ¼kleyin.")
    else:
        with st.spinner("Siyam aÄŸÄ± karÅŸÄ±laÅŸtÄ±rÄ±yor..."):
            # Tahmin
            distance = model.predict([feat_ref, feat_test], verbose=0)[0][0]
            
            st.metric("Hesaplanan Benzerlik Mesafesi", f"{distance:.4f}")
            
            if distance < THRESHOLD:
                st.success(f"âœ… EÅžLEÅžME BAÅžARILI! (Mesafe {THRESHOLD}'dan kÃ¼Ã§Ã¼k)")
                st.balloons()
            else:
                st.error(f"â›” EÅžLEÅžME BAÅžARISIZ! (Mesafe {THRESHOLD}'dan bÃ¼yÃ¼k)")